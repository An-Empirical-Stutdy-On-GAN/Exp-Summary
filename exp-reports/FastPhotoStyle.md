I've tried Nvidia's FastPhotoStyle in the last week, along with the training of CycleGAN using udacity day and Oxford robocar night dataset.

The FastPhotoStyle yields following results:

![100](../imgs/FastPhotoStyle/100.jpg)



â€‹			![30](../imgs/FastPhotoStyle/30.jpg)

![rain](../imgs/FastPhotoStyle/rain.png)

![5](../imgs/FastPhotoStyle/5.jpg)

Whose style images are respectively night(Oxford, with sufficient yellow street light), night(Oxford with little light), rain(Oxford rain), sandstorm(Derived from Internet), the content image are all from udacity dataset. The first of them is a surprising good result since it gives a "normal" result like an autumn style, nevertheless the original style is just like this:    ![img_738_2](../imgs/FastPhotoStyle/img_738_2.png)

However, it still needs proper style image to generate ideal images. And further conclusion may be drawn after more tests.